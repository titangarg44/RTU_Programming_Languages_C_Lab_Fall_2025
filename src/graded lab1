// Name and ID: Sandeep Garg 241ADB010
// Github link:
// https://github.com/titangarg44/RTU_Programming_Languages_C_Lab_Fall_2025

// Compile with: gcc -O2 -Wall -Wextra -std=c17 -o calc calc.c
// Run examples:
//  ./calc input.txt
//  ./calc -d inputs_dir
//  ./calc -d inputs_dir -o outdir

/*
 * calc.c
 *
 * A recursive-descent arithmetic expression evaluator in C implementing
 * (mostly) Pythonic operator rules as required by the assignment.
 *
 * Features included (aimed at Grade 10):
 *  - Integers (long long) and doubles (IEEE 754) with mixed arithmetic
 *  - Binary operators: + - * / and ** (exponentiation, right-associative)
 *  - Unary + and -
 *  - Parentheses ( )
 *  - Proper operator precedence & associativity
 *  - Error reporting with precise 1-based character positions counting '\n'
 *  - Division-by-zero detection (reports position of divisor token)
 *  - Comments: lines where first non-space char is '#'
 *  - Batch mode: -d/--dir processes all *.txt files (no recursion)
 *  - Output dir support: -o/--output-dir (creates if missing)
 *  - Default output folder: <input_base>_<username>_<studentid>
 *    (user must edit first source line to set their name/studentid)
 *
 * Implementation notes and sources:
 *  - Tokenizer & recursive descent inspired by classical parsers and K&R
 *    (see: Kernighan & Ritchie, and numerous online examples).
 *  - Prompt used with ChatGPT (for guidance only): "recursive descent parser in
 * C for arithmetic" (cite required by assignment when using AI assistance).
 *
 * Error strategy:
 *  - Track the first failure position (1-based char index). On first error,
 *    parsing/evaluation stops and output is ERROR:<pos> (single line).
 *  - Token objects carry a start_pos for precise pointing.
 *
 * Limitations / behavior choices:
 *  - On mixed int/double operations, result is double. If final double is
 *    mathematically integral within 1e-12, printed as integer (no decimal).
 *  - Integer overflow is not specially handled (wrap/undefined behavior
 * possible).
 *  - Exponentiation uses pow() for doubles. For integer**integer where
 *    both are small-ish, pow is used and cast; overflow not checked.
 */

#include <ctype.h>
#include <dirent.h>
#include <errno.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

// ----------------------------- Configuration -------------------------------
// Replace these placeholders on submission: first source line must be
// "Name Lastname StudentID" per assignment instructions.
// We also use these to create default output folder and filenames.
#define SUBMITTER_NAME "Name"
#define SUBMITTER_LASTNAME "Lastname"
#define SUBMITTER_ID "StudentID"

// Print tolerance to decide if a double is integral
#define INTEGRAL_EPS 1e-12

// Max path buffer
#define PATH_MAX_LEN 4096

// ------------------------------- Tokenizer --------------------------------

enum TokenKind {
  TK_EOF,
  TK_NUM,
  TK_PLUS,
  TK_MINUS,
  TK_STAR,
  TK_SLASH,
  TK_POW,  // **
  TK_LPAREN,
  TK_RPAREN,
  TK_INVALID,
};

typedef struct {
  enum TokenKind kind;
  long start_pos;  // 1-based char index in file
  long end_pos;    // inclusive
  // for numbers:
  char* lexeme;  // null-terminated substring (allocated)
} Token;

typedef struct {
  const char* buf;  // file buffer
  long len;         // buffer length
  long idx;         // 0-based index into buf
  long char_pos;    // 1-based character position for next char
  int error_set;
  long error_pos;  // first error position (1-based)
} Lexer;

// Helper: set first error position if not set yet
static void set_error_pos(Lexer* lx, long pos) {
  if (!lx->error_set) {
    lx->error_set = 1;
    lx->error_pos = pos;
  }
}

// Peek next char or 0 if EOF
static char lx_peek(Lexer* lx) {
  if (lx->idx >= lx->len) return '\0';
  return lx->buf[lx->idx];
}

// Get and advance one char
static char lx_next(Lexer* lx) {
  if (lx->idx >= lx->len) return '\0';
  char c = lx->buf[lx->idx++];
  lx->char_pos++;
  return c;
}

// Create a token (allocates lexeme if needed)
static Token make_token(enum TokenKind k, long start, long end, const char* lex,
                        long len) {
  Token t;
  t.kind = k;
  t.start_pos = start;
  t.end_pos = end;
  if (lex && len > 0) {
    t.lexeme = (char*)malloc(len + 1);
    memcpy(t.lexeme, lex, len);
    t.lexeme[len] = '\0';
  } else {
    t.lexeme = NULL;
  }
  return t;
}

static void free_token(Token* t) {
  if (t->lexeme) free(t->lexeme);
  t->lexeme = NULL;
}

// Skip whitespace but treat '\n' as countable char (it is counted in char_pos
// already)
static void lx_skip_spaces(Lexer* lx) {
  while (1) {
    char c = lx_peek(lx);
    if (c == ' ' || c == '\t' || c == '\r' || c == '\n') {
      lx_next(lx);
    } else
      break;
  }
}

// If current line (from current position backwards to last '\n' or start) has
// first non-space '#', we should skip the whole line as a comment. The
// assignment says: "Ignore full lines that start with # (Pythonic line
// comments)." That means if first non-space char of a line is '#', skip to end
// of line. Implemented by checking prior char to detect start of line.
static int lx_at_line_start_ignorable(Lexer* lx) {
  // find start of current line index
  long scan = lx->idx;
  // move backward until before buffer start or after a '\n'
  while (scan - 1 >= 0 && lx->buf[scan - 1] != '\n') scan--;
  // scan points to first char of line
  long i = scan;
  // skip spaces
  while (i < lx->len &&
         (lx->buf[i] == ' ' || lx->buf[i] == '\t' || lx->buf[i] == '\r'))
    i++;
  if (i < lx->len && lx->buf[i] == '#') return 1;
  return 0;
}

// Skip comment line (advance to after next '\n' or EOF)
static void lx_skip_comment_line(Lexer* lx) {
  while (lx->idx < lx->len) {
    char c = lx_next(lx);
    if (c == '\n') break;
  }
}

// Extract next token
static Token lx_next_token(Lexer* lx) {
  // Skip spaces but also skip lines that are comments
  while (1) {
    // If at start of a line and first non-space is '#', skip whole line
    if (lx_at_line_start_ignorable(lx)) {
      lx_skip_comment_line(lx);
      continue;
    }
    // else skip normal whitespace
    char c = lx_peek(lx);
    if (c == ' ' || c == '\t' || c == '\r' || c == '\n') {
      lx_skip_spaces(lx);
      continue;
    }
    break;
  }

  long start_pos = lx->char_pos;
  char c = lx_peek(lx);
  if (c == '\0')
    return make_token(TK_EOF, lx->char_pos, lx->char_pos - 1, NULL, 0);

  // Numbers: integer or float. We accept formats suitable for strtod.
  if (isdigit(c) ||
      (c == '.' &&
       isdigit((lx->idx + 1 < lx->len) ? lx->buf[lx->idx + 1] : '\0'))) {
    long p = lx->idx;
    int seen_dot = 0;
    int seen_exp = 0;
    if (lx->buf[p] == '0') {
      // leading zero allowed; still read digits
      p++;
    }
    // We will use strtod on substring; so consume an allowed number pattern
    while (p < lx->len) {
      char cc = lx->buf[p];
      if (isdigit(cc)) {
        p++;
        continue;
      }
      if ((cc == '.' || cc == 'e' || cc == 'E' || cc == '+' || cc == '-')) {
        // '.' only within mantissa; 'e'/'E' start exponent; '+'/'-' may be sign
        // in exponent
        if (cc == '.') {
          if (seen_dot) break;
          seen_dot = 1;
          p++;
          continue;
        }
        if (cc == 'e' || cc == 'E') {
          if (seen_exp) break;
          seen_exp = 1;
          p++;
          // allow optional + or - after e/E
          if (p < lx->len && (lx->buf[p] == '+' || lx->buf[p] == '-')) p++;
          continue;
        }
        // '+' or '-' here should only be allowed immediately after e/E;
        // otherwise break We'll be conservative and break
        break;
      }
      break;
    }
    long len = p - lx->idx;
    Token t = make_token(TK_NUM, start_pos, start_pos + len - 1,
                         lx->buf + lx->idx, len);
    // advance lexer
    for (long i = 0; i < len; i++) lx_next(lx);
    return t;
  }

  // Operators and punctuation
  if (c == '+') {
    lx_next(lx);
    return make_token(TK_PLUS, start_pos, lx->char_pos - 1, NULL, 0);
  }
  if (c == '-') {
    lx_next(lx);
    return make_token(TK_MINUS, start_pos, lx->char_pos - 1, NULL, 0);
  }
  if (c == '*') {
    // might be '**' or '*'
    lx_next(lx);
    if (lx_peek(lx) == '*') {
      lx_next(lx);
      return make_token(TK_POW, start_pos, lx->char_pos - 1, NULL, 0);
    }
    return make_token(TK_STAR, start_pos, lx->char_pos - 1, NULL, 0);
  }
  if (c == '/') {
    lx_next(lx);
    return make_token(TK_SLASH, start_pos, lx->char_pos - 1, NULL, 0);
  }
  if (c == '(') {
    lx_next(lx);
    return make_token(TK_LPAREN, start_pos, lx->char_pos - 1, NULL, 0);
  }
  if (c == ')') {
    lx_next(lx);
    return make_token(TK_RPAREN, start_pos, lx->char_pos - 1, NULL, 0);
  }

  // Unknown char -> invalid token
  // consume it so we advance
  lx_next(lx);
  set_error_pos(lx, start_pos);
  return make_token(TK_INVALID, start_pos, lx->char_pos - 1, NULL, 0);
}

// ------------------------------- Parser ----------------------------------

// Value representation: either integer or double
typedef struct {
  int is_int;  // 1 if integer, 0 if double
  long long ival;
  double dval;
} Value;

static Value make_int(long long v) {
  Value x;
  x.is_int = 1;
  x.ival = v;
  x.dval = (double)v;
  return x;
}
static Value make_double(double v) {
  Value x;
  x.is_int = 0;
  x.dval = v;
  x.ival = (long long)llround(v);
  return x;
}

// Promote to double
static double val_to_double(Value v) {
  return v.is_int ? (double)v.ival : v.dval;
}

// Addition
static Value val_add(Value a, Value b) {
  if (a.is_int && b.is_int) return make_int(a.ival + b.ival);
  return make_double(val_to_double(a) + val_to_double(b));
}
static Value val_sub(Value a, Value b) {
  if (a.is_int && b.is_int) return make_int(a.ival - b.ival);
  return make_double(val_to_double(a) - val_to_double(b));
}
static Value val_mul(Value a, Value b) {
  if (a.is_int && b.is_int) return make_int(a.ival * b.ival);
  return make_double(val_to_double(a) * val_to_double(b));
}
static Value val_div(Value a, Value b) {
  // If both ints, perform integer division with truncation toward zero (C
  // semantics)
  if (a.is_int && b.is_int) return make_int(a.ival / b.ival);
  return make_double(val_to_double(a) / val_to_double(b));
}
static Value val_pow(Value a, Value b) {
  // Use double pow for generality
  double r = pow(val_to_double(a), val_to_double(b));
  // If both were ints and the result is integral, keep int
  if (a.is_int && b.is_int) {
    double ir = round(r);
    if (fabs(r - ir) < INTEGRAL_EPS) return make_int((long long)ir);
  }
  return make_double(r);
}

// Parser state
typedef struct {
  Lexer* lx;
  Token cur;
  int have_error;  // if set, parser should stop
  long error_pos;  // first error pos (copied from lexer)
} Parser;

static void parser_set_error(Parser* ps, long pos) {
  if (!ps->have_error) {
    ps->have_error = 1;
    ps->error_pos = pos;
  }
}

// Forward declarations
static Value parse_expr(Parser* ps);

static void parser_next(Parser* ps) {
  free_token(&ps->cur);
  ps->cur = lx_next_token(ps->lx);
  if (ps->lx->error_set) parser_set_error(ps, ps->lx->error_pos);
}

// Expect current token kind, otherwise error (point at current token start)
static int accept(Parser* ps, enum TokenKind k) {
  if (ps->cur.kind == k) {
    parser_next(ps);
    return 1;
  }
  return 0;
}

static void expect(Parser* ps, enum TokenKind k) {
  if (ps->cur.kind != k) {
    // if at EOF, position should be EOF pos (cur.start_pos)
    parser_set_error(ps, ps->cur.start_pos);
  } else
    parser_next(ps);
}

// parse_primary := NUMBER | '(' expr ')'
static Value parse_primary(Parser* ps) {
  if (ps->have_error) return make_int(0);
  if (ps->cur.kind == TK_NUM) {
    // decide int or double
    const char* s = ps->cur.lexeme;
    // if contains '.' or 'e' or 'E' then double
    int is_double = 0;
    for (const char* p = s; *p; p++)
      if (*p == '.' || *p == 'e' || *p == 'E') {
        is_double = 1;
        break;
      }
    Value v;
    if (is_double) {
      errno = 0;
      char* endp = NULL;
      double d = strtod(s, &endp);
      if (errno != 0 || endp == s) {
        parser_set_error(ps, ps->cur.start_pos);
        v = make_double(0.0);
      } else
        v = make_double(d);
    } else {
      errno = 0;
      char* endp = NULL;
      long long i = strtoll(s, &endp, 10);
      if (errno != 0 || endp == s) {
        parser_set_error(ps, ps->cur.start_pos);
        v = make_int(0);
      } else
        v = make_int(i);
    }
    parser_next(ps);
    return v;
  }
  if (ps->cur.kind == TK_LPAREN) {
    long open_pos = ps->cur.start_pos;
    parser_next(ps);
    Value v = parse_expr(ps);
    if (ps->have_error) return v;
    if (ps->cur.kind != TK_RPAREN) {
      // unmatched '(' -> report error at expected position: either at EOF or at
      // current token
      parser_set_error(ps, ps->cur.start_pos);
      return v;
    }
    parser_next(ps);
    return v;
  }
  // unexpected token
  parser_set_error(ps, ps->cur.start_pos);
  return make_int(0);
}

// parse_unary := ('+'|'-') unary | primary
static Value parse_unary(Parser* ps) {
  if (ps->have_error) return make_int(0);
  if (ps->cur.kind == TK_PLUS) {
    parser_next(ps);
    return parse_unary(ps);
  }
  if (ps->cur.kind == TK_MINUS) {
    parser_next(ps);
    Value v = parse_unary(ps);
    if (v.is_int) return make_int(-v.ival);
    return make_double(-v.dval);
  }
  return parse_primary(ps);
}

// parse_power := unary ('**' power)?  (right-associative)
static Value parse_power(Parser* ps) {
  if (ps->have_error) return make_int(0);
  Value left = parse_unary(ps);
  if (ps->have_error) return left;
  if (ps->cur.kind == TK_POW) {
    long op_pos = ps->cur.start_pos;
    parser_next(ps);
    Value right = parse_power(ps);  // right-assoc
    if (ps->have_error) return left;
    // exponentiation by zero or negative handled normally
    Value res = val_pow(left, right);
    return res;
  }
  return left;
}

// parse_term := factor { ('*' | '/') factor }
// but our grammar with power: term := factor { ('*'|'/') factor }
// where factor is parse_power
static Value parse_term(Parser* ps) {
  if (ps->have_error) return make_int(0);
  Value v = parse_power(ps);
  if (ps->have_error) return v;
  while (ps->cur.kind == TK_STAR || ps->cur.kind == TK_SLASH) {
    int is_div = (ps->cur.kind == TK_SLASH);
    long op_pos = ps->cur.start_pos;
    enum TokenKind op = ps->cur.kind;
    parser_next(ps);
    Value rhs = parse_power(ps);
    if (ps->have_error) return v;
    if (is_div) {
      // check division by zero
      int divisor_is_zero = 0;
      if (rhs.is_int)
        divisor_is_zero = (rhs.ival == 0);
      else
        divisor_is_zero = (fabs(rhs.dval) == 0.0);
      if (divisor_is_zero) {
        parser_set_error(ps, rhs.ival);

        // We cannot use rhs.ival as position; need token pos. To follow spec,
        // we report at start of divisor token.
      }
    }
    if (op == TK_STAR)
      v = val_mul(v, rhs);
    else
      v = val_div(v, rhs);
  }
  return v;
}

// The above had a bug: we need token position when division by zero. Modify:
// capture rhs start pos via parser->cur? But we've already advanced. Simpler:
// modify parse_term to capture rhs token start by looking at last token
// consumed. To avoid complexity, we'll restructure parse_term below properly.

// We'll rewrite parse_term correctly here.
static Value parse_term2(Parser* ps) {
  if (ps->have_error) return make_int(0);
  Value v = parse_power(ps);
  if (ps->have_error) return v;
  while (ps->cur.kind == TK_STAR || ps->cur.kind == TK_SLASH) {
    enum TokenKind op = ps->cur.kind;
    long op_pos = ps->cur.start_pos;
    parser_next(ps);
    // rhs token's start position is ps->cur.start_pos
    long rhs_pos = ps->cur.start_pos;
    Value rhs = parse_power(ps);
    if (ps->have_error) return v;
    if (op == TK_STAR) {
      v = val_mul(v, rhs);
    } else {
      // division
      int divisor_is_zero = 0;
      if (rhs.is_int)
        divisor_is_zero = (rhs.ival == 0);
      else
        divisor_is_zero = (fabs(rhs.dval) == 0.0);
      if (divisor_is_zero) {
        parser_set_error(ps, rhs_pos);
        return v;
      }
      v = val_div(v, rhs);
    }
  }
  return v;
}

// parse_expr := term { ('+' | '-') term }
static Value parse_expr(Parser* ps) {
  if (ps->have_error) return make_int(0);
  Value v = parse_term2(ps);
  if (ps->have_error) return v;
  while (ps->cur.kind == TK_PLUS || ps->cur.kind == TK_MINUS) {
    enum TokenKind op = ps->cur.kind;
    long op_pos = ps->cur.start_pos;
    parser_next(ps);
    Value rhs = parse_term2(ps);
    if (ps->have_error) return v;
    if (op == TK_PLUS)
      v = val_add(v, rhs);
    else
      v = val_sub(v, rhs);
  }
  return v;
}

// Top-level parse function
static int parse_and_eval(Lexer* lx, Value* out_val, long* out_error_pos) {
  Parser ps;
  ps.lx = lx;
  ps.have_error = 0;
  ps.error_pos = 0;
  ps.cur = make_token(TK_INVALID, 0, 0, NULL, 0);

  parser_next(&ps);  // load first token
  Value v = parse_expr(&ps);
  if (!ps.have_error) {
    if (ps.cur.kind != TK_EOF) {
      // extra token after expression
      parser_set_error(&ps, ps.cur.start_pos);
    }
  }

  if (ps.have_error) {
    *out_error_pos = ps.error_pos;
    free_token(&ps.cur);
    return 0;
  }
  *out_val = v;
  free_token(&ps.cur);
  return 1;
}

// ------------------------------ File I/O ---------------------------------

// Read whole file into buffer; returns allocated buffer and length (not
// null-terminated necessarily)
static char* read_file(const char* path, long* out_len) {
  FILE* f = fopen(path, "rb");
  if (!f) return NULL;
  if (fseek(f, 0, SEEK_END) != 0) {
    fclose(f);
    return NULL;
  }
  long len = ftell(f);
  if (len < 0) {
    fclose(f);
    return NULL;
  }
  if (fseek(f, 0, SEEK_SET) != 0) {
    fclose(f);
    return NULL;
  }
  char* buf = (char*)malloc(len + 1);
  if (!buf) {
    fclose(f);
    return NULL;
  }
  size_t r = fread(buf, 1, len, f);
  fclose(f);
  buf[len] = '\0';
  if ((long)r != len) {
    free(buf);
    return NULL;
  }
  *out_len = len;
  return buf;
}

static int ensure_dir(const char* path) {
  struct stat st;
  if (stat(path, &st) == 0) {
    if (S_ISDIR(st.st_mode)) return 1;
    return 0;  // exists but not dir
  }
  // create
  if (mkdir(path, 0775) == 0) return 1;
  return 0;
}

// Helper to get base filename (without directory)
static const char* base_name(const char* path) {
  const char* p = strrchr(path, '/');
  if (!p) p = strrchr(path, '\\');
  return p ? p + 1 : path;
}

// Helper to remove .txt extension if present
static void strip_txt_ext(char* s) {
  size_t n = strlen(s);
  if (n > 4 && strcmp(s + n - 4, ".txt") == 0) s[n - 4] = '\0';
}

// Write output: either numeric result or ERROR:<pos>
static int write_output_file(const char* outdir, const char* infile, Value v,
                             int ok, long errpos) {
  char inbase[PATH_MAX_LEN];
  strncpy(inbase, base_name(infile), PATH_MAX_LEN - 1);
  inbase[PATH_MAX_LEN - 1] = '\0';
  strip_txt_ext(inbase);
  char outname[PATH_MAX_LEN];
  snprintf(outname, sizeof(outname), "%s_%s_%s_%s.txt", inbase, SUBMITTER_NAME,
           SUBMITTER_LASTNAME, SUBMITTER_ID);

  char outpath[PATH_MAX_LEN];
  snprintf(outpath, sizeof(outpath), "%s/%s", outdir, outname);

  FILE* f = fopen(outpath, "w");
  if (!f) return 0;
  if (!ok) {
    fprintf(f, "ERROR:%ld\n", errpos);
  } else {
    if (v.is_int) {
      fprintf(f, "%lld\n", (long long)v.ival);
    } else {
      double dv = v.dval;
      double rounded = round(dv);
      if (fabs(dv - rounded) < INTEGRAL_EPS) {
        // integral
        fprintf(f, "%lld\n", (long long)llround(dv));
      } else {
        char buf[128];
        snprintf(buf, sizeof(buf), "%.15g", dv);
        fprintf(f, "%s\n", buf);
      }
    }
  }
  fclose(f);
  return 1;
}

// Process single file: reads, tokenizes by lexer in memory, parses & evaluates,
// writes output
static int process_file(const char* path, const char* outdir) {
  long len;
  char* buf = read_file(path, &len);
  if (!buf) {
    fprintf(stderr, "Failed to read %s\n", path);
    return 0;
  }
  Lexer lx;
  lx.buf = buf;
  lx.len = len;
  lx.idx = 0;
  lx.char_pos = 1;  // positions are 1-based
  lx.error_set = 0;
  lx.error_pos = 0;

  Value result;
  long errpos = 0;
  int ok = parse_and_eval(&lx, &result, &errpos);
  if (!ok) {
    // prefer lexer error if set
    if (lx.error_set) errpos = lx.error_pos;
  }

  int write_ok = write_output_file(outdir, path, result, ok, errpos);
  free(buf);
  if (!write_ok) {
    fprintf(stderr, "Failed to write output for %s\n", path);
    return 0;
  }
  return 1;
}

// Process directory: all *.txt files (no recursion)
static int process_dir(const char* dirpath, const char* outdir) {
  DIR* d = opendir(dirpath);
  if (!d) {
    fprintf(stderr, "Cannot open directory %s\n", dirpath);
    return 0;
  }
  struct dirent* ent;
  while ((ent = readdir(d)) != NULL) {
    if (ent->d_type == DT_REG || ent->d_type == DT_UNKNOWN) {
      const char* name = ent->d_name;
      size_t n = strlen(name);
      if (n >= 4 && strcmp(name + n - 4, ".txt") == 0) {
        char path[PATH_MAX_LEN];
        snprintf(path, sizeof(path), "%s/%s", dirpath, name);
        if (!process_file(path, outdir)) {
          // continue processing others
          fprintf(stderr, "Error processing %s\n", path);
        }
      }
    }
  }
  closedir(d);
  return 1;
}

// ------------------------------- CLI -------------------------------------

static void usage(const char* prog) {
  fprintf(stderr,
          "Usage: %s [-d DIR | --dir DIR] [-o OUTDIR | --output-dir OUTDIR] "
          "input.txt\n",
          prog);
}

int main(int argc, char** argv) {
  const char* dirarg = NULL;
  const char* outdir = NULL;
  const char* inputfile = NULL;

  // Simple arg parsing
  for (int i = 1; i < argc; i++) {
    if (strcmp(argv[i], "-d") == 0 || strcmp(argv[i], "--dir") == 0) {
      if (i + 1 >= argc) {
        usage(argv[0]);
        return 1;
      }
      dirarg = argv[++i];
    } else if (strcmp(argv[i], "-o") == 0 ||
               strcmp(argv[i], "--output-dir") == 0) {
      if (i + 1 >= argc) {
        usage(argv[0]);
        return 1;
      }
      outdir = argv[++i];
    } else if (argv[i][0] == '-') {
      usage(argv[0]);
      return 1;
    } else {
      inputfile = argv[i];
    }
  }

  if (!dirarg && !inputfile) {
    usage(argv[0]);
    return 1;
  }

  // Determine default outdir if not provided:
  // <input_base>_<username>_<studentid>
  char default_outdir[PATH_MAX_LEN];
  if (!outdir) {
    const char* ref = dirarg ? dirarg : inputfile;
    // take base name
    char tmp[PATH_MAX_LEN];
    strncpy(tmp, base_name(ref), PATH_MAX_LEN - 1);
    tmp[PATH_MAX_LEN - 1] = '\0';
    strip_txt_ext(tmp);
    snprintf(default_outdir, sizeof(default_outdir), "%s_%s_%s", tmp,
             SUBMITTER_NAME, SUBMITTER_ID);
    outdir = default_outdir;
  }

  // ensure outdir exists
  if (!ensure_dir(outdir)) {
    fprintf(stderr, "Failed to create or access output dir %s\n", outdir);
    return 1;
  }

  int overall_ok = 1;
  if (dirarg) {
    overall_ok = process_dir(dirarg, outdir);
  } else {
    overall_ok = process_file(inputfile, outdir);
  }

  if (!overall_ok) return 1;
  return 0;
}
